{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nltk.corpus.stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Define an iterator that yields a line of the document per iteration**\n",
    "    - You need an iterator if the document has a lot of lines and you don't want to load them all in at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for line in open(self.fname):\n",
    "            words = line.split()\n",
    "            word\n",
    "            yield "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line_iterator = MySentences('raw_sentences.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Print the first few lines of the document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', ',', 'he', 'says', 'now', '.']\n",
      "['And', 'what', 'did', 'he', 'do', '?']\n",
      "['The', 'money', \"'s\", 'there', '.']\n",
      "['That', 'was', 'less', 'than', 'a', 'year', 'ago', '.']\n"
     ]
    }
   ],
   "source": [
    "line_iterator2 = MySentences('raw_sentences.txt')\n",
    "for i, line in enumerate(line_iterator2):\n",
    "    if i > 3:\n",
    "        break\n",
    "    print line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Train a word2vec model**\n",
    "    - `sg=1` means skip-gram is used\n",
    "    - `workers=4` means use 4 cores\n",
    "    - `size=100` means the layer is of size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 6.13 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model = gensim.models.Word2Vec(sentences=line_iterator, size=100, min_count=1, sg=1, seed=42, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=line_iterator, size=100, min_count=1, sg=1, seed=42, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('night', 0.7559455633163452),\n",
       " ('week', 0.7236725091934204),\n",
       " ('game', 0.6129457950592041),\n",
       " ('year', 0.609284520149231),\n",
       " ('season', 0.6008633971214294),\n",
       " ('off', 0.5410240292549133),\n",
       " ('May', 0.492523193359375),\n",
       " ('On', 0.48334595561027527),\n",
       " ('office', 0.4796464145183563),\n",
       " ('days', 0.46643078327178955)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Saving the model to a binary file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from six import iteritems\n",
    "def save_sampled_word_vectors(vocab_syn0_tup, fname, binary):\n",
    "    vocab, syn0 = vocab_syn0_tup\n",
    "    assert len(vocab) == syn0.shape[0]\n",
    "    with utils.smart_open(fname, 'wb') as fout:\n",
    "        fout.write(utils.to_utf8(\"%s %s\\n\" % syn0.shape))\n",
    "        # store in sorted order: most frequent words at the top\n",
    "        for word, vocab in sorted(iteritems(vocab), key=lambda item: -item[1].count):\n",
    "            row = syn0[vocab.index]\n",
    "            if binary:\n",
    "                fout.write(utils.to_utf8(word) + b\" \" + row.tostring())\n",
    "            else:\n",
    "                fout.write(utils.to_utf8(\"%s %s\\n\" % (word, ' '.join(\"%f\" % val for val in row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_sampled_word_vectors((model.vocab, model.syn0), 'raw_sentence_word2vec_alt.txt', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_word2vec_format('raw_sentence_word2vec.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_word2vec_format('raw_sentence_word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day -0.075769 0.426146 -0.065635 -0.202406 -0.001413 0.223627 -0.115254 -0.055489 0.090441 -0.213343 -0.188934 -0.110624 -0.240913 -0.055284 -0.037003 -0.209487 -0.407531 -0.036872 -0.112005 0.578992 0.116271 0.129044 0.240499 -0.020116 0.061565 -0.079783 0.031827 -0.063596 -0.391882 0.246715 -0.096211 0.495102 0.385679 -0.140752 0.060129 -0.197037 0.017463 -0.087697 0.082446 -0.048656 0.066171 -0.132582 0.410399 -0.169088 0.053762 -0.292791 -0.042287 0.048132 -0.051564 -0.323221 -0.269820 0.170764 -0.155793 -0.158371 0.023382 -0.185978 -0.527142 -0.011020 0.285565 -0.037519 -0.170292 -0.254911 -0.002080 -0.019666 -0.057464 0.026621 0.163694 -0.053668 -0.047269 -0.129903 -0.116750 0.117310 -0.108700 0.356108 0.075504 -0.112164 0.063923 -0.376701 -0.010347 0.059203 -0.161422 0.338747 -0.159119 0.429067 0.242076 0.098549 0.127159 -0.047817 0.200157 -0.198079 -0.309752 0.106777 -0.113941 -0.044359 -0.176312 0.370763 -0.142137 -0.319157 0.375068 0.567709\r\n",
      "today 0.045677 -0.205757 0.120596 -0.077668 -0.087405 0.069399 -0.076886 0.056572 -0.041735 -0.057223 -0.015994 -0.024774 0.065379 0.090484 -0.068384 -0.025627 -0.122584 0.048399 -0.023306 0.214136 -0.091064 0.013748 -0.050404 0.200534 -0.085442 -0.028706 0.195931 -0.000824 -0.095431 0.093625 -0.118888 -0.014172 0.169547 -0.174406 0.116288 0.162173 -0.071184 0.111666 -0.086682 0.075602 -0.052015 -0.013194 0.044164 0.033122 -0.029728 -0.095513 0.011557 -0.032574 0.105674 -0.197800 0.004767 -0.000358 0.114541 0.061755 0.045637 0.032005 -0.030300 -0.043600 0.081824 -0.119075 -0.054196 0.051263 0.080596 -0.248819 -0.033082 0.012370 -0.021754 -0.090034 0.175267 -0.093069 -0.037861 -0.029834 -0.148216 -0.089522 0.002107 0.043232 -0.085105 -0.109478 -0.029554 0.048430 -0.056507 -0.074547 -0.007584 -0.035569 0.082486 -0.125414 -0.117948 -0.142380 0.095123 -0.203123 0.044825 0.021762 -0.055560 -0.087017 -0.025887 -0.029491 0.047530 0.153098 0.065164 0.067726\r\n",
      "days 0.248501 0.185000 -0.236946 0.069033 0.306637 0.382294 -0.068145 -0.108430 0.189855 0.041850 -0.134362 0.018176 -0.360613 0.111780 0.063428 0.018113 -0.358249 -0.117635 0.050719 0.163000 0.077736 0.203872 0.044267 -0.022138 0.100990 0.052260 0.010858 -0.090577 0.020474 0.133821 -0.529229 0.363152 0.338425 -0.129696 -0.142333 -0.209024 0.094495 -0.262854 -0.190161 0.297356 -0.140583 -0.319671 0.511165 -0.062666 0.015337 -0.182251 -0.409891 0.165782 0.217667 -0.488407 -0.060849 0.042934 -0.111572 -0.094636 0.063449 -0.502528 -0.287237 0.002962 0.281502 0.073655 -0.083692 -0.164038 -0.062936 0.057930 -0.261730 -0.265889 0.277440 0.282822 0.045235 0.152485 -0.222702 -0.081647 -0.432804 -0.092218 0.316999 -0.094449 -0.149319 -0.509385 0.007286 -0.039676 -0.145634 0.472923 0.148201 -0.183319 -0.043628 0.005987 0.222058 0.070253 -0.324215 -0.021090 -0.087143 0.239422 0.449197 0.111115 0.103898 0.337523 -0.054450 -0.269639 -0.450357 0.116276\r\n",
      "Today 0.042564 0.077832 0.342853 0.016053 0.170769 0.220463 0.184168 0.063648 -0.113813 -0.053380 -0.025640 -0.094642 0.157395 -0.113348 -0.097000 0.122081 -0.097308 -0.002190 -0.054701 0.153863 -0.118257 -0.081545 -0.270319 -0.043853 -0.014674 -0.104929 0.418000 -0.080278 -0.417508 0.058574 -0.214199 0.106391 0.174845 -0.049918 -0.102851 0.116750 0.087531 0.074172 -0.175157 0.208221 -0.128121 -0.368185 0.223465 0.174820 0.239361 -0.047090 -0.147179 -0.044710 0.115446 -0.304809 -0.009428 -0.143236 0.117975 -0.026966 0.162961 -0.006576 0.004092 -0.165775 0.040711 -0.043435 -0.171846 -0.051105 0.293694 -0.134754 0.066973 0.078247 0.141749 0.000960 0.007334 -0.105937 0.091156 0.088785 -0.086825 -0.030804 -0.080674 -0.086193 0.163399 -0.071468 0.196129 0.041835 -0.147908 0.012237 -0.079754 0.046743 -0.023159 0.223869 0.013899 -0.027078 0.280095 0.024096 -0.095628 -0.234228 0.200084 0.202074 -0.182458 0.190627 0.104391 0.039569 0.101026 -0.007207\r\n",
      "yesterday -0.003307 -0.004587 0.147191 -0.168644 0.018462 0.080172 0.024306 -0.040206 -0.093597 -0.073061 0.002655 -0.066040 0.192558 0.082275 -0.097072 -0.118784 -0.130560 0.163672 -0.070519 0.151249 -0.010119 0.083081 -0.047579 -0.063662 -0.016863 -0.022538 0.164055 -0.042208 0.060176 0.053323 -0.025932 0.075896 0.096770 -0.120140 0.083186 0.072473 0.034313 0.073676 -0.063907 0.034047 -0.098318 -0.140247 0.302889 0.077529 0.027224 -0.057517 -0.048183 -0.052310 0.012670 -0.172803 0.136760 -0.015066 -0.169828 -0.108102 0.020948 -0.012708 0.085836 -0.160451 0.064212 -0.101664 0.004656 0.053467 0.086077 -0.317230 0.042939 -0.041761 0.088547 -0.064463 -0.113013 -0.043053 0.050519 -0.052622 -0.002425 0.125680 0.019273 -0.034695 0.069396 -0.240604 0.009150 -0.047288 -0.154572 -0.098531 -0.194692 -0.113638 0.012897 -0.081693 0.037335 -0.255552 0.057153 -0.056830 -0.052509 0.012041 0.143101 -0.139407 -0.167179 0.006682 0.083909 0.151916 0.141788 -0.003637\r\n",
      "Yesterday -0.019866 0.044913 0.099335 -0.005498 0.118200 0.054876 0.032370 -0.024507 -0.011202 -0.007336 0.058856 -0.055625 0.108476 0.014329 -0.089385 0.006766 -0.008875 0.028762 0.013434 0.099973 -0.006954 0.047980 -0.108349 0.021649 0.012498 -0.032246 0.149702 -0.024729 -0.083119 0.093816 -0.170186 0.127143 0.091333 -0.087686 -0.040955 0.058438 0.040690 -0.001921 -0.062289 0.094310 -0.053726 -0.178316 0.203449 0.073114 0.113139 0.017748 -0.090113 -0.055717 0.040969 -0.167007 0.055705 -0.090443 -0.011416 -0.070110 0.119720 -0.036750 0.031013 -0.064006 0.073685 0.005368 -0.016736 -0.023813 0.123667 -0.105209 0.023066 0.024802 0.043238 0.059197 -0.041629 -0.017182 0.081390 0.005893 0.001854 -0.005202 0.003366 -0.147605 0.050347 -0.107024 0.047137 -0.023892 -0.085937 0.049364 -0.094252 -0.062119 -0.051331 0.048442 0.020504 -0.040229 0.049728 0.081669 -0.053988 -0.083783 0.094548 0.027683 -0.045912 0.109145 0.135899 0.033067 0.032620 0.015268\r\n"
     ]
    }
   ],
   "source": [
    "!grep day raw_sentence_word2vec.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07576926,  0.42614639, -0.06563481, -0.20240588, -0.0014128 ,\n",
       "        0.22362684, -0.11525359, -0.05548898,  0.0904412 , -0.21334273,\n",
       "       -0.1889343 , -0.11062394, -0.24091266, -0.05528387, -0.03700271,\n",
       "       -0.2094871 , -0.40753129, -0.03687177, -0.11200472,  0.57899189,\n",
       "        0.11627138,  0.12904392,  0.24049881, -0.02011611,  0.06156468,\n",
       "       -0.0797834 ,  0.03182727, -0.06359574, -0.39188227,  0.24671496,\n",
       "       -0.09621136,  0.49510199,  0.38567945, -0.14075217,  0.06012853,\n",
       "       -0.19703694,  0.01746314, -0.08769712,  0.08244622, -0.04865608,\n",
       "        0.06617107, -0.13258238,  0.41039905, -0.16908839,  0.05376206,\n",
       "       -0.29279104, -0.04228741,  0.04813201, -0.05156419, -0.32322097,\n",
       "       -0.26982012,  0.17076375, -0.15579265, -0.15837137,  0.02338156,\n",
       "       -0.18597765, -0.52714157, -0.01101984,  0.28556529, -0.03751927,\n",
       "       -0.17029184, -0.25491059, -0.00207992, -0.019666  , -0.05746353,\n",
       "        0.0266208 ,  0.16369438, -0.05366763, -0.047269  , -0.12990294,\n",
       "       -0.11674953,  0.11730974, -0.10869966,  0.35610771,  0.07550401,\n",
       "       -0.11216355,  0.06392331, -0.37670055, -0.01034726,  0.05920337,\n",
       "       -0.16142221,  0.33874679, -0.1591185 ,  0.42906687,  0.24207576,\n",
       "        0.09854886,  0.12715857, -0.04781673,  0.20015709, -0.19807889,\n",
       "       -0.30975178,  0.10677666, -0.11394055, -0.04435905, -0.17631176,\n",
       "        0.37076339, -0.1421369 , -0.31915671,  0.37506831,  0.56770855], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
