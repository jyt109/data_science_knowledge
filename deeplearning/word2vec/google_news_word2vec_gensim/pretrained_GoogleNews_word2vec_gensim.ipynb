{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import utils\n",
    "import numpy as np\n",
    "from six import iteritems\n",
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **You can load in word vectors trained by Google News documents**\n",
    "    - The file is 1.5GB and is not included in the repo, but you can download it\n",
    "    - Note that download and loading it in will take a while (Loading will take ~5 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2015-08-06 16:25:39--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
      "Resolving s3.amazonaws.com... 54.231.10.24\n",
      "Connecting to s3.amazonaws.com|54.231.10.24|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1647046227 (1.5G) [application/x-gzip]\n",
      "Saving to: 'GoogleNews-vectors-negative300.bin.gz'\n",
      "\n",
      "GoogleNews-vectors- 100%[=====================>]   1.53G  2.01MB/s   in 11m 15s\n",
      "\n",
      "2015-08-06 16:36:54 (2.33 MB/s) - 'GoogleNews-vectors-negative300.bin.gz' saved [1647046227/1647046227]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.word2vec.Word2Vec.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **You can query the most similar words to the list of words you are interested in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'shoes', 0.7552986145019531),\n",
       " (u'footwear', 0.6774437427520752),\n",
       " (u'sneaker', 0.6722689270973206),\n",
       " (u'Shoe', 0.6581934690475464),\n",
       " (u'sandal', 0.629105806350708),\n",
       " (u'sneakers', 0.6061371564865112),\n",
       " (u'slipper', 0.5994482040405273),\n",
       " (u'sandals', 0.5673254728317261),\n",
       " (u'Shoes', 0.559785783290863),\n",
       " (u'sock', 0.5576707720756531)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['shoe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **You can query the most similar words to the list of words you are interested in**\n",
    "    - And exclude words related to concepts you are not interested in\n",
    "    - `sandals` are exlcude when `beach` is included as a negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Shoe', 0.4694807231426239),\n",
       " (u'shoes', 0.43661928176879883),\n",
       " (u'retailer_Footstar', 0.389981210231781),\n",
       " (u'orthotics', 0.3796594440937042),\n",
       " (u'footwear', 0.3790792226791382),\n",
       " (u'sneaker', 0.3684130609035492),\n",
       " (u'athletic_footwear', 0.36705636978149414),\n",
       " (u'Shoes', 0.36504432559013367),\n",
       " (u'Aokang_Group', 0.35710006952285767),\n",
       " (u'shoemaker', 0.3485073745250702)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['shoe'], negative=['beach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **All the word vectors are stored in the attribute `syn0`**\n",
    "    - There are `3,000,000` words, each represented by `300` dimensions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **All the words in the model are stored in the attribute `index2word`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'</s>',\n",
       " u'in',\n",
       " u'for',\n",
       " u'that',\n",
       " u'is',\n",
       " u'on',\n",
       " u'##',\n",
       " u'The',\n",
       " u'with',\n",
       " u'said']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.index2word[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **You can access the vector of the word with indexing retrieval**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "[-0.00453209 -0.0220217   0.04964008 -0.03796006 -0.02822671  0.03066005\n",
      "  0.12750687 -0.07884012  0.00827335 -0.04818008]\n"
     ]
    }
   ],
   "source": [
    "print model['said'].shape\n",
    "print model['said'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **The model as it stands is too big, so I am going to subsample the word vectors and write it to new files**\n",
    "    - I am going to pick `30`, `3000`, `300000` and give myself the freedom to decide how long I want to wait\n",
    "    - There is no built-in to sample a word2vec model, so I am going to implement one here\n",
    "    - Note it is not memory-optimized and takes around 5 mins to sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_word_vectors(model, n):\n",
    "    sampled_vocab = dict(random.sample(model.vocab.items(), n))\n",
    "    syn0 = model.syn0\n",
    "    counter = 0\n",
    "    new_vocab = {}\n",
    "    new_syn0_lst = []\n",
    "    for word, vocab in sampled_vocab.iteritems():\n",
    "        vocab_copy = copy.deepcopy(vocab)\n",
    "        old_index = vocab.index\n",
    "        vocab_copy.index = counter\n",
    "        assert vocab_copy.index != old_index\n",
    "        counter += 1\n",
    "        new_vocab[word] = vocab_copy\n",
    "        new_syn0_lst.append(syn0[old_index])\n",
    "    return new_vocab, np.array(new_syn0_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_30_tup = sample_word_vectors(model, 30)\n",
    "sampled_3000_tup = sample_word_vectors(model, 3000)\n",
    "sampled_300000_tup = sample_word_vectors(model, 300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_sampled_word_vectors(vocab_syn0_tup, fname, binary):\n",
    "    vocab, syn0 = vocab_syn0_tup\n",
    "    assert len(vocab) == syn0.shape[0]\n",
    "    with utils.smart_open(fname, 'wb') as fout:\n",
    "        fout.write(utils.to_utf8(\"%s %s\\n\" % syn0.shape))\n",
    "        # store in sorted order: most frequent words at the top\n",
    "        for word, vocab in sorted(iteritems(vocab), key=lambda item: -item[1].count):\n",
    "            row = syn0[vocab.index]\n",
    "            if binary:\n",
    "                fout.write(utils.to_utf8(word) + b\" \" + row.tostring())\n",
    "            else:\n",
    "                fout.write(utils.to_utf8(\"%s %s\\n\" % (word, ' '.join(\"%f\" % val for val in row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_sampled_word_vectors(sampled_30_tup, 'data/google_news_30.bin.gz', True)\n",
    "save_sampled_word_vectors(sampled_3000_tup, 'data/google_news_3000.bin.gz', True)\n",
    "save_sampled_word_vectors(sampled_300000_tup, 'data/google_news_300000.bin.gz', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_sampled_word_vectors(sampled_30_tup, 'data/google_news_30.txt', False)\n",
    "save_sampled_word_vectors(sampled_3000_tup, 'data/google_news_3000.txt', False)\n",
    "save_sampled_word_vectors(sampled_300000_tup, 'data/google_news_300000.txt', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Test if the subsampled models can be loaded back**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_30_from_binary = gensim.models.word2vec.Word2Vec.load_word2vec_format('data/google_news_30.bin.gz', binary=True)\n",
    "model_30_from_txt = gensim.models.word2vec.Word2Vec.load_word2vec_format('data/google_news_30.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_30_from_binary.syn0.shape == (30, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_30_from_binary.vocab) == 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_word = model_30_from_binary.vocab.iterkeys().next()\n",
    "all(model_30_from_binary[random_word] == model[random_word])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
